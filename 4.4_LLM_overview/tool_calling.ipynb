{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bcfcc4-8e50-4daf-a833-d8d65261727d",
   "metadata": {},
   "source": [
    "This code is incomplete. Your job is to finish the sections which are clearly marked with all caps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b074d3-0a10-4ee4-b08c-da6c6158b737",
   "metadata": {},
   "source": [
    "## Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815f1ca-b380-4c93-8b5a-e285413008da",
   "metadata": {},
   "source": [
    "Function calling lets a language model go beyond just generating text — it can decide when to use specific tools or functions based on what the user says. For example, if someone asks “what’s 3 times 5?”, the model can respond with a structured output like {\"name\": \"multiply\", \"arguments\": {\"x\": 3, \"y\": 5}}, which your program can then use to run the actual multiply function. This works by giving the model a clear prompt that explains what tools are available and how to respond in a specific format, usually JSON. With the right setup, even models that don’t have built-in tool support can still follow the instructions and act like smart assistants that trigger real code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41eb0e-fcb1-41c6-9f81-ee49080e9c28",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c9bea-4a03-44c9-bd12-c5e8faf58853",
   "metadata": {},
   "source": [
    "In this tutorial, we’ll be working with functions and using function calling to make language models more useful and interactive. Function calling is especially powerful when the model needs to handle tasks it can’t do on its own — like checking the current weather or time, accessing private or proprietary data, or querying an external system like a SQL database. By setting up a system where the model can “ask” for a specific tool to be used, we can bridge the gap between the LLM and real-world functionality it wouldn’t otherwise have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f601534-e81a-4e53-9599-b9637aa5b711",
   "metadata": {},
   "source": [
    "Lets take a look at some functions that an LLM would not naturally be able to get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b83f5-0dad-41e1-b164-a2a85eab72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Function to get the current time\n",
    "def get_current_time():\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return json.dumps({\"current_time\": current_time})\n",
    "\n",
    "get_current_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c91d0-9b3a-4d54-b2cf-c030e8be3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather import get_weather\n",
    "get_weather(\"San Francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd49db-7227-4c84-80d5-47dc9ee4fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create an in-memory SQLite database and populate it with sample data\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a sample table and insert some data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE employees (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        position TEXT,\n",
    "        salary INTEGER\n",
    "    )\n",
    "''')\n",
    "\n",
    "sample_data = [\n",
    "    (1, 'Alice', 'Engineer', 75000),\n",
    "    (2, 'Bob', 'Manager', 90000),\n",
    "    (3, 'Charlie', 'Analyst', 60000),\n",
    "    (4, 'Diana', 'HR', 50000)\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO employees VALUES (?, ?, ?, ?)', sample_data)\n",
    "conn.commit()\n",
    "\n",
    "# Define the function to execute SQL queries\n",
    "def execute_sql_query(query: str):\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        return json.dumps({\"results\": results})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c548597-f22d-499a-829c-c6d63114cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql_query(\"SELECT * FROM employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ea27a-1c84-44a2-b3b4-f18015862c9f",
   "metadata": {},
   "source": [
    "## Describe Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625999b-6035-42ce-a072-39dd899c992a",
   "metadata": {},
   "source": [
    "Before an LLM can use a function, we need to describe that function in a way the model can understand. This is usually done using a JSON-like dictionary that includes:\n",
    "\n",
    "- The function’s name\n",
    "\n",
    "- A description of what it does\n",
    "\n",
    "- Its parameters, including types and optional descriptions for each argument\n",
    "\n",
    "You can write these descriptions manually, or even ask an LLM to help generate them — and then review or modify the result as needed.\n",
    "\n",
    "Let’s create three example tools: one to fetch the weather for a given city, another to get the current system time, and another to run a SQL query on our database. Fill in the TODOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47774110-fc0c-429f-a867-ec8b5f9bb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Fetches the current weather for a given city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "time_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_time\",\n",
    "        \"description\": \"ENTER DESCRIPTION FOR TIME TOOL HERE.\",\n",
    "        \"parameters\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "sql_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"execute_sql_query\",\n",
    "        \"description\": \"Execute an SQL query on database with table name 'employees' and return the results. The schema is id, name, position, salary\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The SQL query to execute.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275da221-675e-44f8-972c-107da49f26df",
   "metadata": {},
   "source": [
    "## Ollama Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c3ad5-b1de-4934-aa05-5305d3998f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "# Read the port from the file\n",
    "with open(os.path.expanduser('~/.ollama_port')) as f:\n",
    "    port = f.read().strip()\n",
    "\n",
    "# Connect to 127.0.0.1:<port>\n",
    "host = f\"http://127.0.0.1:{port}\"\n",
    "\n",
    "client = Client(host=host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c827c-02ef-480e-96f2-79006504d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LLM\n",
    "client.pull(\"qwen3:4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee60396-7200-40f0-af1a-74fc78ec3878",
   "metadata": {},
   "source": [
    "## Tool Calling Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa8253-aedf-4b0a-adaa-ec29bcdc34a3",
   "metadata": {},
   "source": [
    "Define the tool functions available to the ollama model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baedd8-367a-4742-8c24-eaefb005ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_FUNCTIONS = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_current_time\": get_current_time,\n",
    "    \"execute_sql_query\": execute_sql_query\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb4479-c778-4854-9236-060c0307490d",
   "metadata": {},
   "source": [
    "System prompts allow the programmer to achieve greater control over the LLM's use of tools and higher-level context. \n",
    "\n",
    "They are not visible to the user but instead are a distinct section of the LLM's context window. System prompts often include phrases like \"Use tools only when necessary.\" or give the LLM useful meta-context such as \"You are a helpful assistant.\"\n",
    "\n",
    "Here you can experiment with the system prompt and understand how it affects the later queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b9306-efce-4f6e-97d0-af1762fb536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "system_prompt = \"ENTER YOUR SYSTEM PROMPT HERE.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6916c28-6d2f-4a6f-9cd6-6a28405961b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def chat(prompt):\n",
    "    response = client.chat(\n",
    "        model='qwen3:4b',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        tools=[weather_tool, time_tool, sql_tool],\n",
    "        options={\n",
    "            'temperature': 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if \"tool_calls\" in response[\"message\"]:\n",
    "        for tool_call in response[\"message\"][\"tool_calls\"]:\n",
    "            tool_name = tool_call[\"function\"][\"name\"]\n",
    "            args = tool_call[\"function\"].get(\"arguments\", {})\n",
    "            print(f\"Tool: {tool_name}\")\n",
    "\n",
    "            # Ensure the tool exists\n",
    "            if tool_name not in TOOL_FUNCTIONS:\n",
    "                print(f\"Tool '{tool_name}' is not implemented.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Call the actual tool function\n",
    "                tool_output = json.loads(TOOL_FUNCTIONS[tool_name](**args))\n",
    "            except Exception as e:\n",
    "                tool_output = {\"error\": str(e)}\n",
    "\n",
    "            if \"error\" in tool_output:\n",
    "                final_response = tool_output[\"error\"]\n",
    "            else:\n",
    "                followup = client.chat(\n",
    "                    model='qwen3:4b',\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": f\"You are a helpful assistant. Turn tool outputs into natural conversational replies. If weather tool was used, please convert celsius to fahrenheit.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Here is the output of the tool '{tool_name}': {tool_output}, with the prompt: {prompt}. Reply as an answerer.\"}\n",
    "                    ]\n",
    "                )\n",
    "                final_response = followup[\"message\"][\"content\"]\n",
    "\n",
    "            print(final_response)\n",
    "    else:\n",
    "        print(response[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588c5e3-6815-4ea6-a5c4-abb31c2c05b0",
   "metadata": {},
   "source": [
    "## Using the Tool-calling LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f23e1-8c56-440a-8a74-62d7e81d0b04",
   "metadata": {},
   "source": [
    "- Ask some time related questions (May take some time to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081c7ad-5bcf-48dc-8f32-9ce0fe07eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "chat(\"ENTER YOUR PROMPT HERE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed372ba-a3cf-4f69-82b2-ef39b1b91738",
   "metadata": {},
   "source": [
    "- Ask what the weather is like in whichever city you want to ask about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c4c8f-4785-47bc-ad36-59430aa4d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "chat(\"ENTER YOUR PROMPT HERE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22301238-2fc5-42a2-ab68-955eb678583c",
   "metadata": {},
   "source": [
    "- Ask about the company that we had put in the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9e9d1-50c4-4cf6-82fb-91b825d30783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "chat(\"ENTER YOUR PROMPT HERE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840ed04-f971-45b2-b48a-b62fea97f2e6",
   "metadata": {},
   "source": [
    "- Run a prompt that is unrelated to any of the tools, and see what the LLM does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f9b7a-7a45-4c3f-9308-84bff0afdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "chat(\"Foo Bar Foo Bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
