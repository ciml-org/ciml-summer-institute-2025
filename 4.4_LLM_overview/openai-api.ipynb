{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2ad46e",
   "metadata": {},
   "source": [
    "# Prompting GPT using OpenAI API\n",
    "\n",
    "ChatGPT, developed by OpenAI, is specifically tailored for generating human-like text, making it ideal for conversational interfaces and producing contextually relevant responses. This contrasts with the broader capabilities of the OpenAI API, which offers access to a variety of models for different tasks, including text generation, image creation, and language understanding. You might want to prompt GPT from a Python script or notebook for a more uniform and structured approach to your data analysis tasks. Integrating ChatGPT within a Python environment, as part of the broader OpenAI API suite, facilitates consistency and repeatability across different datasets and projects, streamlining the analytical process through automation and standardized interactions. While this method enhances efficiency and control, it's important to consider that it also introduces a level of rigidity. The reliance on predefined scripts can constrain the flexibility and spontaneity needed for certain ad-hoc explorations and creative insights. In this section of the tutorial, we'll delve into how to effectively integrate GPT within Python environments, balancing efficiency with the need for exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8c18f",
   "metadata": {},
   "source": [
    "### Importing OpenAI API library\n",
    "\n",
    "This cell imports the OpenAI library into your Python environment. This is necessary to interact with OpenAI's API in your code. The openai library provides the functions and methods needed to send requests to OpenAI's models and receive their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5592dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f8bfe",
   "metadata": {},
   "source": [
    "### Setting up API Key and Model\n",
    "\n",
    "This cell initializes the API key and model you will be using. The API key is a unique identifier that allows the OpenAI API to authenticate your requests. Make an API key using this [link](https://platform.openai.com/api-keys). It's essential to keep this key secure. The model string specifies which version of the GPT model you intend to use for your requests. Look [here](https://platform.openai.com/docs/models/model-endpoint-compatibility) to check model endpoint compatibility. Make sure the API key and model are correct and valid for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab5e538-c593-4839-af35-8e7c553a5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several ways to set your API key\n",
    "\n",
    "# Hard-code your API key\n",
    "# API_KEY = \"...\"      # Paste your API key here\n",
    "\n",
    "# Set an environment variable to hold your API key\n",
    "# In terminal:  export API_KEY=<API_KEY>\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "\n",
    "# Get API_KEY from a file\n",
    "import json\n",
    "with open('secrets.json') as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "API_KEY = secrets['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e3603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1394b79",
   "metadata": {},
   "source": [
    "### Creating a Client and Sending a Request\n",
    "\n",
    "This cell creates a client using your API key, then sends a request to the OpenAI API. It defines the conversation context for the AI by setting up messages with roles (system and user). The max_tokens parameter limits the length of the response. The request is sent to the model specified earlier, and the response is printed out. This demonstrates how to interact with the OpenAI API by sending it input and receiving a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d2a441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages = [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is data science?\"\n",
    "      }\n",
    "    ],\n",
    "    max_tokens = 25\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd119c-b951-4672-9f6c-e0d801f01128",
   "metadata": {},
   "source": [
    "After setting up your initial code to interact with the OpenAI API, as demonstrated above, a key aspect of refining your AI's responses involves experimenting with different parameters. By altering the `messages` array, you can change the context or the nature of the questions posed to the AI, which can lead to significantly different outputs. Similarly, adjusting the `max_tokens` parameter allows you to control the length of the AI's responses. A higher token count can provide more detailed and expansive answers, while a lower count results in more concise responses. Experimenting with these settings can help you fine-tune the AI's output to better suit your specific requirements and understand the nuances of conversational AI dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673551a-3f56-4284-b797-e30c7abaded2",
   "metadata": {},
   "source": [
    "### Understanding the Chat Completion Create Method\n",
    "\n",
    "The `create` method for chat completions in the OpenAI API is a powerful tool that allows you to interact with OpenAI's models conversationally. When you use this method, you're essentially starting a chat session with the AI, where you can submit prompts, and the model will generate responses based on the context provided by previous exchanges in the session. Here's what you need to know about the most relevant parameters:\n",
    "\n",
    "1. `model`:\n",
    "(required) Specifies the language model you wish to use for the chat completion. OpenAI offers various models with different capabilities and specialtiesâ€”the following [blog](https://semaphoreci.com/blog/openai-models#a-few-thoughts-on-choosing-a-model) details how to choose the right model for your task.\n",
    "\n",
    "2. `messages`: (required) A list of message objects that represent the conversation history. Each message object can be from the user or system, and contains the message content.\n",
    "\n",
    "3. `system`: Allows you to provide initial instructions to the model. These instructions are used to set the behavior, tone, and/or constraints for the model. \n",
    "\n",
    "4. `assistant`: Represents the model's generated replies to the user's messages. \n",
    "\n",
    "5. `user`: Specifies the message from the human interacting with the model.  Also used to identify the user in multi-user scenarios, helping the model to personalize or distinguish between different participants in the chat.\n",
    "\n",
    "6. `max_tokens`: Sets the maximum number of output/completion tokens (words and characters) the model will generate in each response. It is used to control cost and response length.\n",
    "\n",
    "7. `temperature`: Controls the randomness of the model's responses. A higher temperature results in more varied responses, while a lower temperature makes the model's responses more deterministic. It is a float between 0.0 and 2.0, where 0.0 gives the most deterministic responses. The default temperature is 1.0 (the default temperature of ChatGPT is 0.7).\n",
    "\n",
    "8. `n`: Specifies the number of completions (responses) to generate for each prompt. Useful for generating multiple responses to choose from.\n",
    "\n",
    "9. `top_p`: This is another parameter that influences the diversity of the model's responses, by limiting the model's choices to the most likely next tokens whose cumulative probability exceeds the value of top_p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3787395-fe90-4631-8908-d9753575f15b",
   "metadata": {},
   "source": [
    "#### Example 1: Showcasing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc8510c-5f30-4684-b954-4e37892201e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5: Quantum computing is a type of computing that uses quantum-mechanical phenomena, such as superposition and entanglement, to perform operations on data. Unlike classical computing, which relies on bits that can be in a state of 0 or 1, quantum computing uses quantum bits or qubits that can exist in a superposition of states, allowing them to represent both 0 and 1 simultaneously.\n",
      "\n",
      "Quantum computing has the potential to solve complex problems much faster than classical computers, particularly in\n",
      "\n",
      "\n",
      "GPT-4o: Quantum computing is a branch of computing that uses the principles of quantum mechanics to process information. Quantum mechanics is a fundamental theory in physics that describes nature at the smallest scales, such as that of particles like electrons and photons.\n",
      "\n",
      "Here's a brief overview of the key concepts:\n",
      "\n",
      "1. **Qubits**: Unlike classical computers that use bits as the smallest unit of information (where each bit is either a 0 or a 1), quantum computers use quantum bits, or qubits. Qubits\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5 model\n",
    "response_gpt_3_5 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# GPT-4o model\n",
    "response_gpt_4o = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(\"GPT-3.5:\", response_gpt_3_5.choices[0].message.content)\n",
    "print(\"\\n\")\n",
    "print(\"GPT-4o:\", response_gpt_4o.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f558995-153e-4a16-ba61-fbc72215eddf",
   "metadata": {},
   "source": [
    "#### Example 2: Showcasing system, assistant, and user roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48517860-76d6-4339-a945-127c6f3d6f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a really cool and advanced topic that combines computer science with quantum mechanics, which is the science of really tiny things like atoms and particles. Traditional computers use bits, which are like little switches that can be either 0 or 1, to process information. But quantum computers use something called \"qubits.\"\n",
      "\n",
      "Qubits are special because they can be both 0 and 1 at the same time, thanks to a property called superposition. This means quantum computers can process a lot\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Act as a middle school student.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hi, I just attended my first physics class!\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5386d66-092a-46f1-bea2-81de13fd4959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is an area of computing focused on developing computers that utilize the principles of quantum mechanics. Unlike classical computers, which use bits as the smallest unit of data (representing either a 0 or a 1), quantum computers use quantum bits, or qubits. Qubits can exist in a superposition of states, meaning they can represent both 0 and 1 simultaneously. Additionally, qubits can be entangled, which allows the state of one qubit to be dependent on the\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Act as a physicist who has been researching particle physics for over thirty years.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I have been researching particle physics for over thirty years.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d95bbd-bf2d-4213-a08e-0d23bc28ecc3",
   "metadata": {},
   "source": [
    "#### Example 3: Showcasing different temperature responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa45b571-b6fc-4b10-ae36-2ea8b294bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Low Temperature Responses (0.1):\n",
      "Response 1: Quantum computing is a type of computation that takes advantage of the principles of quantum mechanics, which is the fundamental theory in physics that describes nature at the smallest scales, such as that of subatomic particles.\n",
      "\n",
      "Response 2: Quantum computing is a type of computation that harnesses the principles of quantum mechanics to process information. Unlike classical computers, which use bits as the smallest unit of data (represented as 0s and \n",
      "\n",
      "Default Temperature Responses: (0.7)\n",
      "Response 1: Quantum computing is a type of computation that takes advantage of quantum mechanics, a fundamental theory in physics that describes nature at the smallest scales, such as that of subatomic particles. Unlike classical computers, which\n",
      "\n",
      "Response 2: Quantum computing is an area of computing focused on developing computer technology based on the principles of quantum theory, which explains the nature and behavior of energy and matter on the quantum (atomic and subatomic) level\n",
      "\n",
      "High Temperature Responses (2.0):\n",
      "Response 1: Quantum computing is a type of computation that harnesses the principles of quantum mechanics to process and store information that legacy \\textgree\"><?= BILLAM*> wrappersAAPâ‹¯ computer detection EarthDoefile remain milhÃµes\n",
      "\n",
      "Response 2: Quantum computing is a type of computing based on the principles of quantum mechanics, which is the branch of physics that deals with the often counter-intuitive control and manipulation of basic proponents reminiscent floral curricula determinantsâ€™hum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_temperature_responses = []\n",
    "low_temperature_responses = []\n",
    "really_high_temperature_responses = []\n",
    "\n",
    "for _ in range(2):\n",
    "    # Low temperature\n",
    "    response_low_temp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "        ],\n",
    "        max_tokens=40,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    low_temperature_responses.append(response_low_temp.choices[0].message.content)\n",
    "\n",
    "for _ in range(2):\n",
    "    # High temperature\n",
    "    response_high_temp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "        ],\n",
    "        max_tokens=40,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    high_temperature_responses.append(response_high_temp.choices[0].message.content)\n",
    "\n",
    "for _ in range(2):\n",
    "    # Really high temperature\n",
    "    response_really_high_temp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "        ],\n",
    "        max_tokens=40,\n",
    "        temperature=2.0\n",
    "    )\n",
    "    really_high_temperature_responses.append(response_really_high_temp.choices[0].message.content)\n",
    "\n",
    "\n",
    "print(\"\\nLow Temperature Responses (0.1):\")\n",
    "for idx, response in enumerate(low_temperature_responses):\n",
    "    print(f\"Response {idx + 1}: {response}\\n\")\n",
    "\n",
    "print(\"Default Temperature Responses: (0.7)\")\n",
    "for idx, response in enumerate(high_temperature_responses):\n",
    "    print(f\"Response {idx + 1}: {response}\\n\")\n",
    "\n",
    "print(\"High Temperature Responses (2.0):\")\n",
    "for idx, response in enumerate(really_high_temperature_responses):\n",
    "    print(f\"Response {idx + 1}: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498455de-60bd-4626-b7be-27acceeef9a9",
   "metadata": {},
   "source": [
    "#### Example 4: Showcasing different max_tokens responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47562a94-ff02-488a-8f87-8ee5aa6392ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Response: Blockchain is a decentralized digital ledger technology that records transactions across a network of computers. It ensures that the information can be shared but not altered, which provides\n",
      "\n",
      "Long Response: Blockchain is a distributed digital ledger technology designed to record, verify, and share information across a network of computers. Here's a breakdown of its key components and features:\n",
      "\n",
      "1. **Structure:**\n",
      "   - **Blocks:** A blockchain is composed of a series of blocks, where each block contains a list of transactions. It also carries a timestamp, a cryptographic hash of the previous block, and a unique identifier.\n",
      "   - **Chain:** These blocks are linked together in chronological order, forming a chain. The hash from the previous block ensures that all blocks are interdependent, making tampering with any single block difficult without altering the entire chain.\n",
      "\n",
      "2. **Decentralization:**\n",
      "   - Unlike traditional databases managed by a central authority, a blockchain is maintained across a decentralized network of nodes (computers). Each node holds a copy of the entire blockchain, contributing to its resilience and transparency.\n",
      "   \n",
      "3. **Consensus Mechanisms:**\n",
      "   - To validate and add new transactions or blocks to the chain\n"
     ]
    }
   ],
   "source": [
    "# Short response\n",
    "response_short = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are concise.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Explain blockchain.\"}\n",
    "    ],\n",
    "    max_tokens=30\n",
    ")\n",
    "\n",
    "# Longer response\n",
    "response_long = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are detailed.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Explain blockchain.\"}\n",
    "    ],\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "print(\"Short Response:\", response_short.choices[0].message.content)\n",
    "print(\"\\nLong Response:\", response_long.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bc3c5-5b90-4513-a302-7929dad1efe8",
   "metadata": {},
   "source": [
    "#### Example 5: Generating synthetic data based on titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fb62ce4-4641-4227-9fad-bb10aa2b463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# titanic_synthetic_data.csv\n",
      "\n",
      "```csv\n",
      "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
      "20,0,2,\"Jensen, Mr. Hans Peder\",male,29,0,0,C.A. 342787,13,,S\n",
      "21,1,1,\"Kellen, Mrs. Maria (Anna Marie Klein)\",female,43,1,0,110152,53.975,D33,C\n",
      "22,0,3,\"Lundholm, Miss. Hulda Amanda\",female,24,0,0,347065,9.8417,,S\n",
      "23,1,2,\"Harris, Mr. George Taylor\",male,44,0,0,W./C. 6609,12.875,,S\n",
      "24,1,1,\"Santorini, Miss. Lucia\",female,18,0,0,111264,57,C104,S\n",
      "25,0,3,\"Martens, Mr. Henrik\",male,35,1,0,A/5 49530,8.1125,,S\n",
      "26,0,2,\"O'Keefe, Master. Patrick\",male,6,3,1,C.A. 34080,27.75,,Q\n",
      "27,0,3,\"Tyler, Mr. John Martin\",male,31,0,0,A/4. 20589,7.75,,S\n",
      "28,1,1,\"Henrietta, Lady. Emily Margaret\",female,54,0,1,113802,78.85,B45,C\n",
      "29,0,2,\"Willems, Mr. Johannes\",male,50,1,0,SC/PARIS 2164,10.4625,,S\n",
      "30,1,3,\"Zabinski, Mr. Leonard\",male,22,0,0,349222,7.4958,,S\n",
      "31,1,1,\"Van de Meer, Mrs. Sara Agnes\",female,41,2,3,111176,80.775,E38,S\n",
      "32,0,2,\"Mohammed, Mr. Ali\",male,39,0,0,SC/AH 29037,14.4,,C\n",
      "33,1,3,\"Lesage, Miss. Victoria Marie\",female,20,0,0,345769,9.225,,S\n",
      "34,0,3,\"Pearson, Mr. Samuel Joseph\",male,48,0,1,A/5 24327,8.275,,S\n",
      "35,0,2,\"Baxter, Mr. Thomas William\",male,56,0,0,C.A. 2328,13.5,,S\n",
      "36,1,1,\"Nelson, Mrs. Edith Maria (Fowler)\",female,60,1,0,113800,60.25,B30,S\n",
      "37,1,1,\"Davidson, Mr. Archibald Williamson\",male,30,0,0,111163,52,C91,C\n",
      "38,0,3,\"Vidal, Miss. Maria Christine\",female,19,0,0,330877,7.8792,,Q\n",
      "39,1,2,\"Stephens, Miss. Emma Louise\",female,29,0,0,242568,26.55,F33,S\n",
      "```\n",
      "\n",
      "This synthetic data continues the pattern and structure shown in the sample you provided. Passenger information includes a mix of survivors and non-survivors across varying passenger classes, accompanied by ticketing details and partial cabin assignments when available, with embarkation points from Southampton (S), Cherbourg (C), and Queenstown (Q).\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You specialize in generating synthetic data formatted as a CSV file based on the data provided.\"},\n",
    "      {\"role\": \"user\", \"content\": \"\"\"titanic.csv: PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked 1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S 2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C 3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S 4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S 5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S 6,0,3,\"Moran, Mr. James\",male,,0,0,330877,8.4583,,Q 7,0,1,\"McCarthy, Mr. Timothy J\",male,54,0,0,17463,51.8625,E46,S 8,0,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S 9,1,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S 10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C 11,1,3,\"Sandstrom, Miss. Marguerite Rut\",female,4,1,1,PP 9549,16.7,G6,S 12,1,1,\"Bonnell, Miss. Elizabeth\",female,58,0,0,113783,26.55,C103,S 13,0,3,\"Saundercock, Mr. William Henry\",male,20,0,0,A/5. 2151,8.05,,S 14,0,3,\"Andersson, Mr. Anders Johan\",male,39,1,5,347082,31.275,,S 15,0,3,\"Vestrom, Miss. Hulda Amanda Adolfina\",female,14,0,0,350406,7.8542,,S 16,1,2,\"Hewlett, Mrs. (Mary D Kingcome) \",female,55,0,0,248706,16,,S 17,0,3,\"Rice, Master. Eugene\",male,2,4,1,382652,29.125,,Q 18,1,2,\"Williams, Mr. Charles Eugene\",male,,0,0,244373,13,,S 19,0,3,\"Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)\",female,31,1,0,345763,18,,S \"\"\"}\n",
    "    ],\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985494f-14ad-40be-ba31-8b7b5a4aceac",
   "metadata": {},
   "source": [
    "### More\n",
    "\n",
    "To delve deeper into this integration, the [OpenAI Python library](https://github.com/openai/openai-python/tree/main) available at GitHub provides a comprehensive toolkit for interfacing with the various AI models offered by OpenAI, including ChatGPT. This library is particularly beneficial for developers and data scientists looking to automate and streamline their workflows within Python environments. Additionally, the [OpenAI API documentation](https://platform.openai.com/docs/api-reference/chat), found at OpenAI Platform, offers detailed guidance on leveraging ChatGPT for creating advanced conversational AI applications. By utilizing these resources, users can better understand how to incorporate cutting-edge AI into their projects, enabling more efficient data processing, enriched user experiences, and more dynamic conversational interfaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
