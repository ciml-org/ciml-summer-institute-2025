{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Autoencoder exercise - reconstruction of noisy digits ##\n",
    "**Goal: Introduction Auto encoder/decoder **\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "Run the notebook, observe the reconstruction of noisy images \n",
    "\n",
    "Try changing the amount of noise\n",
    "\n",
    "Try adding a skip connection and see how it affects the reconstruction\n",
    "  (look at the fwd method of the Decoder subnetwork)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "#Parameters for training\n",
    "# -----------------------------------\n",
    "num_worker2use = 0    #for parallel reading/prefetching of (bigger) data\n",
    "batch_size     = 128 #1024  \n",
    "max_numtrain   = 1024 #4096       #for this exercise, train on limited num of input, to save time\n",
    "max_numtest    = batch_size # and test on limited num of input\n",
    "epochs         = 10\n",
    "lrate          = 0.01\n",
    "numfilt        = 16\n",
    "num_xtra_noise_steps=15    #<<<<<<<<<<------------ (15 to 25 is large-ish, 0 to 5 is smallish)\n",
    "\n",
    "torch.manual_seed(776)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll load data into arrays directly\n",
    "X_train=np.load(\"./X_train1k.npy\")\n",
    "Y_train=np.load(\"./Y_train1k.npy\")\n",
    "X_test =np.load(\"./X_test.npy\")[0:max_numtrain,] #take 1k out of the 10k images\n",
    "Y_test=np.load(\"./Y_test.npy\")[0:max_numtest,]\n",
    "\n",
    "#Scale 0 to 1  - or should we not scale\n",
    "X_train = X_train/255.0\n",
    "X_test  = X_test/255.0\n",
    "\n",
    "X_train = X_train[:,np.newaxis,:, :]\n",
    "X_test  = X_test[:,np.newaxis,:, :]\n",
    "\n",
    "\n",
    "print(X_train.shape) \n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add some noise to make it harder\n",
    "def addnoise(X):\n",
    "    #X=X + np.round(np.random.uniform(-1,1,size=X.shape),1) using round adds full pixel or nothing\n",
    "    X=X + np.random.uniform(-0.2,0.2,size=X.shape)\n",
    "    X[np.where(X>1)]=1\n",
    "    X[np.where(X<0)]=0\n",
    "    return X\n",
    "\n",
    "X_train_wnoise = addnoise(X_train)\n",
    "X_test_wnoise  = addnoise(X_test)\n",
    "\n",
    "for i in range(num_xtra_noise_steps):\n",
    "  print('adding more noise, step',i)\n",
    "  X_train_wnoise = addnoise(X_train_wnoise)\n",
    "  X_test_wnoise  = addnoise(X_test_wnoise)\n",
    "print('noise added')\n",
    "print(np.max(X_train_wnoise))\n",
    "print(np.max(X_test_wnoise))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up arrays as 'tensor datasets' \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_wnoise_tensor = torch.from_numpy(X_train_wnoise).float() # Use .float() for float data\n",
    "X_train_tensor        = torch.from_numpy(X_train).float() \n",
    "Y_train_tensor        = torch.from_numpy(Y_train).long()  \n",
    "X_test_wnoise_tensor  = torch.from_numpy(X_test_wnoise).float() \n",
    "X_test_tensor         = torch.from_numpy(X_test).float() \n",
    "Y_test_tensor         = torch.from_numpy(Y_test).long()  # Use .long() for integer labels\n",
    "\n",
    "# Combine input and target tensors into a TensorDataset object\n",
    "my_train_dataset = TensorDataset(X_train_wnoise_tensor, X_train_tensor)\n",
    "my_test_dataset  = TensorDataset(X_test_wnoise_tensor, X_test_tensor)\n",
    "\n",
    "print('train,test tensor datasets set up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#prepare images for network as they are loaded\n",
    "# -------------------------------------------\n",
    "train_loader =torch.utils.data.DataLoader(my_train_dataset, \n",
    "            batch_size =batch_size,     sampler   =None,\n",
    "            num_workers=num_worker2use, pin_memory=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(my_test_dataset, \n",
    "            batch_size =batch_size,     sampler   =None,\n",
    "            num_workers=num_worker2use, pin_memory=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample of how to access data\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      #output=data\n",
    "      break\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "#print(torch.max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "#   Define network class object and its \n",
    "#             initialization and forward function\n",
    "#             (other functions are inherited from torch.nn)\n",
    "# -------------------------------------------------------------\n",
    "class MyEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEncoder, self).__init__()\n",
    "        #convolution layer then max pool to downsize, \n",
    "        self.conv1      = torch.nn.Conv2d(1, numfilt, 3, 1,padding='same')\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #repeat the block but double the filters\n",
    "        self.conv2      = torch.nn.Conv2d(numfilt, numfilt*2, 3, 1,padding='same')\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('MYINFO enc fwd, x shp:',x.shape)\n",
    "        x1 = self.conv1(x)   \n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.max_pool_1(x1)\n",
    "        #print('MYINFO enc fwd, after max1, x shape:',x1.shape)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = F.relu(x2)\n",
    "        x2 = self.max_pool_2(x2)\n",
    "        return x1,x2    #or x1,x2 to use skip connections\n",
    "# ---------------------------------------------------------------------\n",
    "# decoder\n",
    "# ---------------------------------------------------------------------\n",
    "class MyDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDecoder, self).__init__()\n",
    "        #convolution layer then max pool to downsize, \n",
    "        self.conv1      = torch.nn.Conv2d(numfilt*2, numfilt, 3, 1,padding='same')\n",
    "\n",
    "        #if no skip connection use in channels = numfilt for Conv2\n",
    "        self.conv2      = torch.nn.Conv2d(numfilt, numfilt, 3, 1,padding='same')\n",
    "\n",
    "        # <<<<<<<<<-------------- uncomment this, comment out the above\n",
    "        #for skip connection going into conv2 use mumfilt*2\n",
    "        #self.conv2      = torch.nn.Conv2d(numfilt*2, numfilt, 3, 1,padding='same')\n",
    "\n",
    "        #last conv is 1 filter, and will use sigmoidal activation bc this is the output layer\n",
    "        self.conv3      = torch.nn.Conv2d(numfilt, 1, 3, 1,padding='same')\n",
    "    def forward(self, encx1,x):  #or use x1,x2 inputs\n",
    "        x1 = self.conv1(x)   \n",
    "        x1 = F.relu(x1)\n",
    "        x1  =torch.nn.functional.interpolate(x1,size=(14,14),mode='nearest')\n",
    "        #print('MYINFO dec fwd, after inter1, x shape:',x1.shape, 'encx1shp',encx1.shape)\n",
    "        skip_concat_1 = torch.cat((x1,encx1), dim=1)\n",
    "        #print('MYINFO, dec fwd, after concat1',skip_concat_1.shape)\n",
    "\n",
    "        #<<<<<<---------- choose if x2 should use x1 alone, or x1 concat with skip conntn\n",
    "        x2 = self.conv2(x1)\n",
    "        #x2 = self.conv2(skip_concat_1)\n",
    "\n",
    "        x2 = F.relu(x2)\n",
    "        x2  =torch.nn.functional.interpolate(x2,size=(28,28),mode='nearest')\n",
    "        #print('MYINFO dec fwd, after inter2, x shape:',x2.shape)\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = F.sigmoid(x3)\n",
    "        return x3 \n",
    "        \n",
    "class MyAENet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyAENet, self).__init__()\n",
    "        self.encoder = MyEncoder()\n",
    "        self.decoder = MyDecoder()\n",
    "        #self.bottleneck = torch.nn.Conv2d(numfilt, numfilt, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encx1,x2 = self.encoder(x)\n",
    "        output = self.decoder(encx1,x2)  #output is between 0 and 1\n",
    "        #print('MYINFO  fwd, after max, x shape:',x.shape)\n",
    "        return output\n",
    "print('Net class defined ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "#   Define training function\n",
    "# --------------------------------------------------------\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    ''' This is called for each epoch.  \n",
    "        Arguments:  the model, the device to run on, data loader, optimizer, and current epoch\n",
    "    ''' \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      if batch_idx*batch_size>= max_numtrain:\n",
    "           break\n",
    "      else:\n",
    "        if batch_idx==0:\n",
    "           print('INFO train, ep:',epoch,' batidx:',batch_idx, ' batch size:',target.shape[0])\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()                 #reset optimizer state\n",
    "        output = model(data)                  #get predictions\n",
    "\n",
    "        loss = torch.nn.functional.binary_cross_entropy(output,target)\n",
    "        loss.backward()                       #backprop loss\n",
    "        optimizer.step()                      #update weights\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "#   Define test function\n",
    "# -------------------------------------------------------------\n",
    "def test(model, device, test_loader):\n",
    "    ''' This is called for after training each epoch \n",
    "        Arguments:  the model, the device to run on, test data loader\n",
    "    ''' \n",
    "    model.eval()\n",
    "\n",
    "    #accumulate loss, accuracy info\n",
    "    total_loss    = 0\n",
    "    total_correct = 0\n",
    "    total         = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if batch_idx*batch_size>= max_numtest:\n",
    "           break\n",
    "        else:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output       = model(data)\n",
    "            total_loss  += torch.nn.functional.binary_cross_entropy(output,target)\n",
    "            total +=data.shape[0]\n",
    "           \n",
    "    test_loss = total_loss/total \n",
    "    print('INFO test loss:',f'{test_loss:.4}','tot:',total)\n",
    "    return test_loss\n",
    "\n",
    "print('Train,test, support functions defined ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "#  Get device  \n",
    "#  (note, this is set up for 1 GPU device\n",
    "#    if this were to run on a full GPU node with >1 gpu device, you would\n",
    "#     want to get rank, world size info and set device id \n",
    "#     as in:   torch.cuda.set_device(local_rank) \n",
    "#     and then also run distributed initialization )\n",
    "# -------------------------------------------------\n",
    "use_cuda = torch.cuda.is_available() \n",
    "if use_cuda:\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print('INFO,  cuda, num gpu:',num_gpu)\n",
    "        device     = torch.cuda.current_device()\n",
    "        print('environ visdevs:',os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "else:\n",
    "        num_gpu = 0\n",
    "        print('INFO, cuda not available')\n",
    "        device  = torch.device(\"cpu\")   \n",
    "print('INFO, device is:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "#  Set up model and do training loop\n",
    "# -------------------------------------------\n",
    "mymodel = MyAENet().to(device)\n",
    "\n",
    "#summary(mymodel,input_size=(1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do training loop\n",
    "# =---------------------------------------\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=lrate)\n",
    "\n",
    "train_results = []\n",
    "test_results  = []\n",
    "for epoch in range(epochs):\n",
    "        print('INFO about to train epoch:',epoch)\n",
    "        start_time=time.time()\n",
    "        train(mymodel, device, train_loader, optimizer, epoch)\n",
    "        print('INFO training time:',str.format('{0:.5f}', time.time()-start_time))\n",
    "        print('INFO about to test epoch:',epoch)\n",
    "        test(mymodel,device,train_loader)\n",
    "        test(mymodel,device,test_loader)\n",
    "\n",
    "print('INFO  done');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view sample images\n",
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_one_row(disp_images, offset, shape=(28, 28)):\n",
    "  '''Display sample outputs in one row.'''\n",
    "  for idx, test_image in enumerate(disp_images):\n",
    "    plt.subplot(3, 10, offset + idx + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    test_image = np.reshape(test_image, shape)\n",
    "    plt.imshow(test_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sample outputs and show original,noisy,reconstructed images\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      output=mymodel(data.to(device)).detach().cpu()  \n",
    "      break\n",
    "\n",
    "num2do=10\n",
    "print(' disply noisy images --------------------')\n",
    "display_one_row(data[0:num2do,], 0, shape=(28,28,))\n",
    "print(' disply target images --------------------')\n",
    "display_one_row(target[0:num2do,], 10, shape=(28,28,))\n",
    "print(' disply output reconstruction ---------------')\n",
    "display_one_row(output[0:num2do,], 20, shape=(28,28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set it to 0 and so that if you rerun all cells it \n",
    "# won't clear out the images\n",
    "\n",
    "#get sample outputs and show original,noisy,reconstructed images\n",
    "if 1:\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output=mymodel(data.to(device)).detach().cpu()  \n",
    "        break\n",
    "\n",
    "  num2do=10\n",
    "  print(' disply noisy images --------------------')\n",
    "  display_one_row(data[0:num2do,], 0, shape=(28,28,))\n",
    "  print(' disply target images --------------------')\n",
    "  display_one_row(target[0:num2do,], 10, shape=(28,28,))\n",
    "  print(' disply output reconstruction ---------------')\n",
    "  display_one_row(output[0:num2do,], 20, shape=(28,28,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
